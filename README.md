# AFP Multi-Source Analytics System

A real-time streaming analytics platform that compares news articles from multiple sources (AFP, Reddit, GDELT) using advanced ML-based analysis with Kafka and Apache Spark.

## ğŸš€ Quick Start

### Prerequisites
- Docker Desktop (latest version)
- Docker Compose (included with Docker Desktop)
- Internet connection for API data sources

### Run the System

\\\powershell
# Navigate to project directory
cd "c:\Users\aitnd\Documents\Efrei Paris\SEMESTRE 7\BIG DATA FRAMEWORK\PROJET"

# Start all services
docker-compose up -d

# Wait 30 seconds for Kafka/Zookeeper to initialize
# Then access the dashboard
Start-Process "http://localhost:8501"
\\\

## ğŸ“Š System Components

### Architecture
- **Zookeeper**: Kafka coordination
- **Kafka Broker**: Message streaming (3 topics)
- **Producer**: Multi-source data ingestion (AFP, Reddit, GDELT)
- **Spark Consumer**: Real-time stream processing + ML analysis
- **Dashboard**: Streamlit visualization (port 8501)
- **Database**: SQLite persistence

### Data Pipeline
1. **Ingestion**: Producer collects articles from 3 sources â†’ Kafka
2. **Streaming**: Kafka distributes messages across 3 topics
3. **Processing**: Spark consumes in real-time (5-second batches)
4. **Analysis**: ML engine generates comprehensive comparison analysis
5. **Storage**: Results stored in SQLite database
6. **Visualization**: Dashboard displays real-time insights

## ğŸ“ˆ ML Analysis Features

Each article comparison includes:
- **Headline Comparison**: Framing and focus differences
- **Content Deformation**: Information integrity scoring (0-100%)
- **Objectivity Assessment**: Bias and editorial stance analysis
- **Sentiment Analysis**: Emotional tone tracking
- **Framing Analysis**: Narrative structure comparison
- **Comprehensive Verdict**: Reliability classification (Low/Moderate/High)

## ğŸ›ï¸ Monitoring & Verification

### Check System Status
\\\powershell
docker-compose ps
\\\

### View Streaming Logs
\\\powershell
docker logs -f afp-spark-consumer
\\\

### Access Database Directly
\\\powershell
docker exec afp-spark-consumer sqlite3 /app/data/afp_realtime_analysis.db
\\\

### Stop the System
\\\powershell
docker-compose down
\\\

## ğŸ“Š Dashboard Features

Access the dashboard at: **http://localhost:8501**

- Real-time comparison statistics
- Source filtering (AFP, Reddit, GDELT)
- Similarity and deformation metrics
- Sentiment distribution
- Trending topics
- Detailed comparison analysis

## ğŸ“ Project Structure

\\\
.
â”œâ”€â”€ docker/                          # Docker orchestration
â”‚   â”œâ”€â”€ docker-compose.yml           # Service definitions
â”‚   â”œâ”€â”€ Dockerfile                   # Python/Spark image
â”‚   â”œâ”€â”€ config/                      # Configuration files
â”‚   â”œâ”€â”€ data/                        # Persistent volumes
â”‚   â””â”€â”€ logs/                        # Docker logs
â”‚
â”œâ”€â”€ src/                             # Source code
â”‚   â”œâ”€â”€ producers/                   # Data ingestion
â”‚   â”‚   â””â”€â”€ afp_realtime_producer_complete.py
â”‚   â”œâ”€â”€ consumers/                   # Stream processing
â”‚   â”‚   â””â”€â”€ spark_afp_realtime_consumer.py
â”‚   â”œâ”€â”€ utils/                       # Utilities
â”‚   â”‚   â””â”€â”€ content_comparator.py
â”‚   â””â”€â”€ dashboard/                   # Visualization
â”‚       â””â”€â”€ dashboard_afp_realtime_complete.py
â”‚
â”œâ”€â”€ docker-compose.yml               # Service orchestration
â”œâ”€â”€ Dockerfile                       # Container image
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .env.template                    # Environment template
â””â”€â”€ README.md                        # This file
\\\

## ğŸ”§ Configuration

### Environment Variables
Copy \.env.template\ to \.env\ and customize:
- \KAFKA_BROKERS\: Kafka connection
- \SPARK_MASTER\: Spark master URL
- \DATABASE_PATH\: SQLite database location
- \REDDIT_KEYWORDS\: Search terms for Reddit
- \GDELT_DATABASE\: GDELT data source

## ğŸ› Troubleshooting

### Containers not starting
\\\powershell
# Clean rebuild
docker-compose down -v
docker-compose build --no-cache
docker-compose up -d
\\\

### Kafka topics not created
\\\powershell
docker-compose logs afp-kafka-init
\\\

### Dashboard not accessible
\\\powershell
docker ps | grep dashboard
docker logs afp-dashboard
\\\

## ğŸ“Š Project Requirements - Verification

âœ… **Multi-Source Data Ingestion**: AFP, Reddit, GDELT  
âœ… **Streaming Data Processing**: Kafka + Spark integration  
âœ… **Text Analysis**: TF-IDF similarity, sentiment scoring  
âœ… **Data Storage**: SQLite with comprehensive schema  
âœ… **Reporting & Visualization**: Streamlit dashboard  
âœ… **Word Counts**: TF-IDF based keyword analysis  
âœ… **Trending Topics**: Keyword extraction and trending  
âœ… **Sentiment Scoring**: VADER sentiment analysis  
âœ… **Anomaly Detection**: Deformation-based alerts  

## ğŸ“ˆ Performance Metrics

- **Processing Speed**: 4-8 matches per 5-second batch
- **Analysis Quality**: 2,000+ character comprehensive reports per comparison
- **Database**: 1,500+ analyzed comparisons with full metadata
- **Memory Usage**: ~2GB for all 6 containers
- **CPU Usage**: 20-30% average

## ğŸ¤ Data Sources

- **AFP**: Simulated news articles (can integrate real API)
- **Reddit**: Real-time Reddit post data via API
- **GDELT**: Global Event, Location and Tone dataset

## ğŸ“ License

Academic project - EFREI Paris

## ğŸ‘¥ Support

For issues or questions, refer to:
- PROJECT_COMPLETION_REPORT.md - Detailed system documentation
- SYSTEM_STATUS.md - Current system status
- Docker logs: \docker-compose logs [service]\

---
**Last Updated**: \2025-11-10 01:23:44
